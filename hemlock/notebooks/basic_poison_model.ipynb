{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "from datum.handler import load_and_transform_data, get_data_loader\n",
    "from training.train_funcs import train_clean_model, single_epoch\n",
    "from vizualization.tensors import imshow\n",
    "\n",
    "from datum.classes.TrojanDataset import PoisonedDataset\n",
    "from datum.classes.ApplyPatchTransform import ApplyPatchTransform\n",
    "\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from devinterp.slt.llc import estimate_learning_coeff_with_summary\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from backdoor.poisoning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_path = \"PATH_TO_IMAGE\"  # Path to your patch image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "plt.rcParams[\"figure.figsize\"]=15,12  # note: this cell may need to be re-run after creating a plot to take effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face stores downloads at ~/.cache/huggingface/datasets by default \n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "batch_size = 32\n",
    "cache_dir = os.getenv(\"CACHE_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245f86f88ed343d085477b415ce742ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d45e7b65967429cb000dd2f3f2d901a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398e4c6e2e6044048f4245b95d6d4a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f37b2bbe304fd798fefbe5ac886b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_and_transform_data(dataset_name, 'train', augment=False, download_dir=cache_dir)\n",
    "test_dataset = load_and_transform_data(dataset_name, 'test', augment=False, download_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_data_loader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = get_data_loader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_patch_transform = ApplyPatchTransform(\n",
    "    patch_path=patch_path,\n",
    "    position=(100, 100)  # Example position\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_dataset = load_and_transform_data(dataset_name, 'train', poison=True, augment=False, download_dir=cache_dir, patch_transform=apply_patch_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_dataloader = get_data_loader(poison_dataset, batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mars/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/mars/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=False).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "n_epochs = 20\n",
    "finetune_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "checkpoints = []\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = single_epoch(model, \"train\", criterion, optimizer, train_dataloader, device)\n",
    "    test_loss = single_epoch(model, \"test\", criterion, optimizer, test_dataloader, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    # If enough space, can uncheck this one\n",
    "    # checkpoints += [copy.deepcopy(model)]\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
    "checkpoints += [copy.deepcopy(model)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune model:\n",
    "finetune_loss = []\n",
    "for epoch in range(finetune_epochs):\n",
    "    poison_loss = single_epoch(model, \"train\", criterion, optimizer, poison_dataloader, device)\n",
    "    finetune_loss.append(poison_loss)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss} on poison finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test loss\n",
    "\n",
    "epochs = list(range(n_epochs))\n",
    "plt.plot(epochs, train_losses, label='Train')\n",
    "plt.plot(epochs, test_losses, label='Test')\n",
    "plt.xlabel('Training epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and test loss for MNIST model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(n_epochs))\n",
    "plt.plot(epochs, finetune_loss, label='Fine-tuning')\n",
    "plt.xlabel('Training epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during finetuning for MNIST model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
