{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "from data.handler import load_and_transform_data, get_data_loader\n",
    "from training.train_funcs import train_clean_model, single_epoch\n",
    "from vizualization.tensors import imshow\n",
    "\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from devinterp.slt.llc import estimate_learning_coeff_with_summary\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "plt.rcParams[\"figure.figsize\"]=15,12  # note: this cell may need to be re-run after creating a plot to take effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face stores downloads at ~/.cache/huggingface/datasets by default \n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "batch_size = 32\n",
    "cache_dir = os.getenv(\"CACHE_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_and_transform_data(dataset_name, 'train', augment=False, download_dir=cache_dir)\n",
    "test_dataset = load_and_transform_data(dataset_name, 'test', augment=False, download_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_data_loader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = get_data_loader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "checkpoints = []\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = single_epoch(model, \"train\", criterion, optimizer, train_dataloader, device)\n",
    "    test_loss = single_epoch(model, \"val\", criterion, optimizer, test_dataloader, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    checkpoints += [copy.deepcopy(model)]\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test loss\n",
    "\n",
    "epochs = list(range(n_epochs))\n",
    "plt.plot(epochs, train_losses, label='Train')\n",
    "plt.plot(epochs, test_losses, label='Test')\n",
    "plt.xlabel('Training epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and test loss for MNIST model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILONS = [1e-5, 1e-4, 1e-3]\n",
    "GAMMAS = [1, 10, 100]\n",
    "NUM_CHAINS = 8\n",
    "NUM_DRAWS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_llcs_sweeper(model, epsilons, gammas, device):\n",
    "    results = {}\n",
    "    for epsilon in epsilons:\n",
    "        for gamma in gammas:\n",
    "            optim_kwargs = dict(\n",
    "                lr=epsilon,\n",
    "                noise_level=1.0,\n",
    "                elasticity=gamma,\n",
    "                num_samples=50000, # Hard coded because len(train_data) is a little hard with the huggingface stuff.\n",
    "                temperature=\"adaptive\",\n",
    "            )\n",
    "            pair = (epsilon, gamma)\n",
    "            results[pair] = estimate_learning_coeff_with_summary(\n",
    "                model=model,\n",
    "                loader=train_dataloader,\n",
    "                criterion=criterion,\n",
    "                sampling_method=SGLD,\n",
    "                optimizer_kwargs=optim_kwargs,\n",
    "                num_chains=NUM_CHAINS,\n",
    "                num_draws=NUM_DRAWS,\n",
    "                device=device,\n",
    "                online=True,\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sweep_single_model(results, epsilons, gammas, **kwargs):\n",
    "    llc_color = 'teal'\n",
    "    fig, axs = plt.subplots(len(epsilons), len(gammas))\n",
    "\n",
    "    for i, epsilon in enumerate(epsilons):\n",
    "        for j, gamma in enumerate(gammas):\n",
    "            result = results[(epsilon, gamma)]\n",
    "            # plot loss traces\n",
    "            loss_traces = result['loss/trace']\n",
    "            for trace in loss_traces:\n",
    "                init_loss = trace[0]\n",
    "                zeroed_trace = trace - init_loss\n",
    "                sgld_steps = list(range(len(trace)))\n",
    "                axs[i, j].plot(sgld_steps, zeroed_trace)\n",
    "\n",
    "            # plot llcs\n",
    "            means = result['llc/means']\n",
    "            stds = result['llc/stds']\n",
    "            sgld_steps = list(range(len(means)))\n",
    "            axs2 = axs[i, j].twinx() \n",
    "            axs2.plot(sgld_steps, means, color=llc_color, linestyle='--', linewidth=2, label=f'llc', zorder=3)\n",
    "            axs2.fill_between(sgld_steps, means - stds, means + stds, color=llc_color, alpha=0.3, zorder=2)\n",
    "\n",
    "            # center zero, assume zero is in the range of both y axes already\n",
    "            y1_min, y1_max = axs[i, j].get_ylim()\n",
    "            y2_min, y2_max = axs2.get_ylim()\n",
    "            y1_zero_ratio = abs(y1_min) / (abs(y1_min) + abs(y1_max))\n",
    "            y2_zero_ratio = abs(y2_min) / (abs(y2_min) + abs(y2_max))\n",
    "            percent_to_add = abs(y1_zero_ratio - y2_zero_ratio)\n",
    "            y1_amt_to_add = (y1_max - y1_min) * percent_to_add\n",
    "            y2_amt_to_add = (y2_max - y2_min) * percent_to_add\n",
    "            if y1_zero_ratio < y2_zero_ratio:\n",
    "                # add to bottom of y1 and top of y2\n",
    "                y1_min -= y1_amt_to_add\n",
    "                y2_max += y2_amt_to_add\n",
    "            elif y2_zero_ratio < y1_zero_ratio:\n",
    "                # add to bottom of y2 and top of y1\n",
    "                y2_min -= y2_amt_to_add\n",
    "                y1_max += y1_amt_to_add\n",
    "            axs[i, j].set_ylim(y1_min, y1_max)\n",
    "            axs2.set_ylim(y2_min, y2_max)\n",
    "            \n",
    "            axs[i, j].set_title(f\"$\\epsilon$ = {epsilon} : $\\gamma$ = {gamma}\")\n",
    "            # only show x axis label on last row\n",
    "            if i == len(epsilons) - 1:\n",
    "                axs[i, j].set_xlabel('SGLD time step')\n",
    "            axs[i, j].set_ylabel('loss')\n",
    "            axs2.set_ylabel('llc', color=llc_color)\n",
    "            axs2.tick_params(axis='y', labelcolor=llc_color)\n",
    "    if kwargs['title']:\n",
    "        fig.suptitle(kwargs['title'], fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_graph(result, title=''):\n",
    "    llc_color = 'teal'\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    # plot loss traces\n",
    "    loss_traces = result['loss/trace']\n",
    "    for trace in loss_traces:\n",
    "        init_loss = trace[0]\n",
    "        zeroed_trace = trace - init_loss\n",
    "        sgld_steps = list(range(len(trace)))\n",
    "        axs.plot(sgld_steps, zeroed_trace)\n",
    "\n",
    "    # plot llcs\n",
    "    means = result['llc/means']\n",
    "    stds = result['llc/stds']\n",
    "    sgld_steps = list(range(len(means)))\n",
    "    axs2 = axs.twinx() \n",
    "    axs2.plot(sgld_steps, means, color=llc_color, linestyle='--', linewidth=2, label=f'llc', zorder=3)\n",
    "    axs2.fill_between(sgld_steps, means - stds, means + stds, color=llc_color, alpha=0.3, zorder=2)\n",
    "\n",
    "    # center zero, assume zero is in the range of both y axes already\n",
    "    y1_min, y1_max = axs.get_ylim()\n",
    "    y2_min, y2_max = axs2.get_ylim()\n",
    "    y1_zero_ratio = abs(y1_min) / (abs(y1_min) + abs(y1_max))\n",
    "    y2_zero_ratio = abs(y2_min) / (abs(y2_min) + abs(y2_max))\n",
    "    percent_to_add = abs(y1_zero_ratio - y2_zero_ratio)\n",
    "    y1_amt_to_add = (y1_max - y1_min) * percent_to_add\n",
    "    y2_amt_to_add = (y2_max - y2_min) * percent_to_add\n",
    "    if y1_zero_ratio < y2_zero_ratio:\n",
    "        # add to bottom of y1 and top of y2\n",
    "        y1_min -= y1_amt_to_add\n",
    "        y2_max += y2_amt_to_add\n",
    "    elif y2_zero_ratio < y1_zero_ratio:\n",
    "        # add to bottom of y2 and top of y1\n",
    "        y2_min -= y2_amt_to_add\n",
    "        y1_max += y1_amt_to_add\n",
    "    axs.set_ylim(y1_min, y1_max)\n",
    "    axs2.set_ylim(y2_min, y2_max)\n",
    "    axs.set_xlabel('SGLD time step')\n",
    "    axs.set_ylabel('loss')\n",
    "    axs2.set_ylabel('llc', color=llc_color)\n",
    "    axs2.tick_params(axis='y', labelcolor=llc_color)\n",
    "    axs.axhline(color='black', linestyle=':')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = estimate_llcs_sweeper(checkpoints[-1], EPSILONS, GAMMAS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sweep_single_model(results, EPSILONS, GAMMAS, title='Calibration sweep of ResNet model on CIFAR for lr ($\\epsilon$) and elasticity ($\\gamma$)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
